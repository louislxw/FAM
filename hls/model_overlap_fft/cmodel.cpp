/*
 * This file was auto-generated by tf2hls.py.
*/

#include "hls_stream.h"
#include "ap_int.h"
#include "hls-nn-lib.h"
#include "cmodel_weights.h"

#include "exp_table.h"
#include "hanning.h"

using namespace hls;

typedef ap_uint<64> CONV1_OUT_T;
typedef ap_uint<64> POOL1_OUT_T;
typedef ap_uint<40> FIRE1_OUT_T;
typedef ap_uint<40> POOL2_OUT_T;
typedef ap_uint<40> FIRE2_OUT_T;
typedef ap_uint<40> POOL3_OUT_T;
typedef ap_uint<40> FIRE3_OUT_T;
typedef ap_int<32> CONV_CLASS_OUT_T;
typedef ap_uint<8> PIXEL_T;
typedef ap_uint<1> PRED_T;

/*** Define AXI-Stream structures ***/
struct axis_in{
	ap_int<16> data;
	bool last;
};
struct axis_out{
	ap_uint<8> data;
	bool last;
};
typedef hls::stream<axis_in> AXIS_IN;
typedef hls::stream<axis_out> AXIS_OUT;
/*** Define AXI-Stream structures ***/

#define IorQ_W 16
#define FFT_W 32
#define PIXEL_W 8

void bit_reverser(
    stream<ap_int<IorQ_W> >& i_in,
    stream<ap_int<IorQ_W> >& q_in,
    stream<ap_int<IorQ_W> >& i_out,
    stream<ap_int<IorQ_W> >& q_out,
	const unsigned reps
) {
	const unsigned indices[64] = {0,32,16,48,8,40,24,56,4,36,20,52,12,44,28,60,2,34,18,50,10,42,26,58,6,38,22,54,14,46,30,62,1,33,17,49,9,41,25,57,5,37,21,53,13,45,29,61,3,35,19,51,11,43,27,59,7,39,23,55,15,47,31,63};

	for (int r = 0; r < reps; r++) {
#pragma HLS PIPELINE II=1

		ap_int<IorQ_W> ibuf[64];
		ap_int<IorQ_W> qbuf[64];

		for (int i = 0; i < 64; i++) {
	#pragma HLS UNROLL
			ibuf[i] = i_in.read();
			qbuf[i] = q_in.read();
		}

		for (int i = 0; i < 64; i++) {
	#pragma HLS UNROLL
			i_out.write(ibuf[indices[i]]);
			q_out.write(qbuf[indices[i]]);
		}
	}

    return;
}

void fft(
    stream<ap_int<IorQ_W> >& i_in,
    stream<ap_int<IorQ_W> >& q_in,
    stream<ap_int<FFT_W> >& fft_out,
	const unsigned num_ffts
) {

FFT_LOOP: for (int r = 0; r < num_ffts; r++) {
#pragma HLS PIPELINE II=1
		ap_int<FFT_W> ibuf[64];
		ap_int<FFT_W> qbuf[64];
		for (int i = 0; i < 64; i++) {
#pragma HLS UNROLL
			// multiply with hanning-window
			ibuf[i] = (ap_int<FFT_W>)((i_in.read() * hanning[i]) >> 8);
			qbuf[i] = (ap_int<FFT_W>)((q_in.read() * hanning[i]) >> 8);
		}

		// size = 2
		int halfsize = 1;
		int tablestep = 32;

		for (int i = 0; i < 64; i += 2) {
#pragma HLS UNROLL
			int k = 0;
			for (int j = i; j < (i+halfsize); j++) {
#pragma HLS PIPELINE II=1
				ap_int<FFT_W> temp_i = ((ibuf[j+halfsize] * exp_table_i[k]) - (qbuf[j+halfsize] * exp_table_q[k])) >> 14;
				ap_int<FFT_W> temp_q = ((ibuf[j+halfsize] * exp_table_q[k]) + (qbuf[j+halfsize] * exp_table_i[k])) >> 14;
				ibuf[j+halfsize] = ibuf[j] - temp_i;
				qbuf[j+halfsize] = qbuf[j] - temp_q;
				ibuf[j] += temp_i;
				qbuf[j] += temp_q;
				k += tablestep;
			}
		}

		// size = 4
		halfsize = 2;
		tablestep = 16;

		for (int i = 0; i < 64; i += 4) {
#pragma HLS UNROLL
			int k = 0;
			for (int j = i; j < (i+halfsize); j++) {
#pragma HLS PIPELINE II=1
				ap_int<FFT_W> temp_i = ((ibuf[j+halfsize] * exp_table_i[k]) - (qbuf[j+halfsize] * exp_table_q[k])) >> 14;
				ap_int<FFT_W> temp_q = ((ibuf[j+halfsize] * exp_table_q[k]) + (qbuf[j+halfsize] * exp_table_i[k])) >> 14;
				ibuf[j+halfsize] = ibuf[j] - temp_i;
				qbuf[j+halfsize] = qbuf[j] - temp_q;
				ibuf[j] += temp_i;
				qbuf[j] += temp_q;
				k += tablestep;
			}
		}

		// size = 8
		halfsize = 4;
		tablestep = 8;

		for (int i = 0; i < 64; i += 8) {
#pragma HLS UNROLL
			int k = 0;
			for (int j = i; j < (i+halfsize); j++) {
#pragma HLS PIPELINE II=1
				ap_int<FFT_W> temp_i = ((ibuf[j+halfsize] * exp_table_i[k]) - (qbuf[j+halfsize] * exp_table_q[k])) >> 14;
				ap_int<FFT_W> temp_q = ((ibuf[j+halfsize] * exp_table_q[k]) + (qbuf[j+halfsize] * exp_table_i[k])) >> 14;
				ibuf[j+halfsize] = ibuf[j] - temp_i;
				qbuf[j+halfsize] = qbuf[j] - temp_q;
				ibuf[j] += temp_i;
				qbuf[j] += temp_q;
				k += tablestep;
			}
		}

		// size = 16
		halfsize = 8;
		tablestep = 4;

		for (int i = 0; i < 64; i += 16) {
#pragma HLS UNROLL
			int k = 0;
			for (int j = i; j < (i+halfsize); j++) {
#pragma HLS PIPELINE II=1
				ap_int<FFT_W> temp_i = ((ibuf[j+halfsize] * exp_table_i[k]) - (qbuf[j+halfsize] * exp_table_q[k])) >> 14;
				ap_int<FFT_W> temp_q = ((ibuf[j+halfsize] * exp_table_q[k]) + (qbuf[j+halfsize] * exp_table_i[k])) >> 14;
				ibuf[j+halfsize] = ibuf[j] - temp_i;
				qbuf[j+halfsize] = qbuf[j] - temp_q;
				ibuf[j] += temp_i;
				qbuf[j] += temp_q;
				k += tablestep;
			}
		}

		// size = 32
		halfsize = 16;
		tablestep = 2;

		for (int i = 0; i < 64; i += 32) {
#pragma HLS UNROLL
			int k = 0;
			for (int j = i; j < (i+halfsize); j++) {
#pragma HLS PIPELINE II=1
				ap_int<FFT_W> temp_i = ((ibuf[j+halfsize] * exp_table_i[k]) - (qbuf[j+halfsize] * exp_table_q[k])) >> 14;
				ap_int<FFT_W> temp_q = ((ibuf[j+halfsize] * exp_table_q[k]) + (qbuf[j+halfsize] * exp_table_i[k])) >> 14;
				ibuf[j+halfsize] = ibuf[j] - temp_i;
				qbuf[j+halfsize] = qbuf[j] - temp_q;
				ibuf[j] += temp_i;
				qbuf[j] += temp_q;
				k += tablestep;
			}
		}

		// size = 64
		halfsize = 32;
		tablestep = 1;

		for (int i = 0; i < 64; i += 64) {
#pragma HLS UNROLL
			int k = 0;
			for (int j = i; j < (i+halfsize); j++) {
#pragma HLS PIPELINE II=1
				ap_int<FFT_W> temp_i = ((ibuf[j+halfsize] * exp_table_i[k]) - (qbuf[j+halfsize] * exp_table_q[k])) >> 14;
				ap_int<FFT_W> temp_q = ((ibuf[j+halfsize] * exp_table_q[k]) + (qbuf[j+halfsize] * exp_table_i[k])) >> 14;
				ibuf[j+halfsize] = ibuf[j] - temp_i;
				qbuf[j+halfsize] = qbuf[j] - temp_q;
				ibuf[j] += temp_i;
				qbuf[j] += temp_q;
				k += tablestep;
			}
		}

		// write out the FFT output (complex conjugate)
		for (int i = 0; i < 64; i++) {
#pragma HLS UNROLL
			ap_int<FFT_W> tmp = ibuf[i]*ibuf[i] + qbuf[i]*qbuf[i];
			fft_out.write(tmp);
		}
	}
}

void averager(
    stream<ap_int<FFT_W> >& fft_in,
    stream<ap_int<FFT_W> >& macro_slice_out,
	const unsigned num_slices
) {
/*
image = np.mean(fft.reshape(FFT_BINS, N_MACRO_SLICES, -1), axis=2)
*/

	ap_int<FFT_W> shift_reg[64][319]; // (256+64-1)
	ap_int<FFT_W*2> acc[64], acc_buf[64];
	#pragma HLS ARRAY_PARTITION variable=shift_reg complete dim=1

	Shift_Accum_Loop: for (int i = 319; i >= 0; i--) {
	#pragma HLS PIPELINE II=1
		for (int j = 0; j < 64; j++) {
		#pragma HLS UNROLL

			if (i == 0) {
				shift_reg[j][0] = fft_in.read();
			} else {
				shift_reg[j][i] = shift_reg[j][i-1];
			}

			acc_buf[j] += shift_reg[j][0];

			if (i > 255) {
				acc_buf[j] = acc_buf[j] - shift_reg[j][256];
				acc[j] = acc_buf[j];
				macro_slice_out.write((ap_int<FFT_W>)(acc[j]/256));
			}
		}
	}
}

void iq2im(
    stream<ap_int<IorQ_W> >& i_in,
    stream<ap_int<IorQ_W> >& q_in,
    stream<ap_uint<PIXEL_W> >& img_out
) {
#pragma HLS DATAFLOW

    stream<ap_int<IorQ_W> > i_rev("i_rev_stream");
    stream<ap_int<IorQ_W> > q_rev("q_rev_stream");
    stream<ap_int<FFT_W> > fft_out("fft_out_stream");
    stream<ap_int<FFT_W> > macro_slice_out("macro_slice_out_stream");

    bit_reverser(i_in, q_in,i_rev, q_rev, 319); // 64*256

    fft(i_rev, q_rev, fft_out, 319); // 64*256

    averager(fft_out, macro_slice_out, 64); // 64

/*
image = (255.0 * image / SIGNAL_MAX)
image[image > 255] = 255
image = image.astype('uint8')
*/

    for (int i = 0; i < 64; i++) {
    	for (int j = 0; j < 64; j++) {
#pragma HLS UNROLL
    		ap_int<FFT_W> v = macro_slice_out.read();
			v = v >> 1;
			v = (v << 8) - v; // multiply by 255
			if (v > 255) {
				img_out.write(255);
			} else {
				img_out.write(0);
			}
    	}
    }
}

// SoftMax<512,64,32,1>(
template<
    unsigned NumTotal,
    unsigned NumClasses,
    unsigned Ibit,
    unsigned Obit>
void SoftMax(
    stream<ap_int<Ibit> >& in,
    stream<ap_uint<Obit> >& out,
    const unsigned reps = 1
) {

    const unsigned NumPreds = NumTotal/(2*NumClasses); // = 512 / (2*64) = 4
    for (int r = 0; r < reps; r++) {
        for (int p = 0; p < NumPreds; p++) {
#pragma HLS UNROLL
            for (int i = 0; i < NumClasses; i++) {
                ap_int<Ibit> v0 = in.read();
                ap_int<Ibit> v1 = in.read();
                if (v1 > v0) {
                    out.write(1);
                } else {
                    out.write(0);
                }
            }
        }
    }
}

void model(
	stream<ap_int<IorQ_W> >& i_in,
	stream<ap_int<IorQ_W> >& q_in,
	stream<PRED_T>& pred_out
//	const unsigned batch_size
) {
#pragma HLS DATAFLOW

	stream<PIXEL_T> image_in("image_in_stream");
	iq2im(i_in,q_in,image_in);

	stream<CONV1_OUT_T> conv1_out_stream("conv1_out_stream");
	// K,S,Din,Cin,Cout,Ibit,Wbit,Mbit,Abit,MVTU_InP,MVTU_OutP,ScaleBits,FactorScaleBits
	CONV2D_ACT_NoP<3,2,64,1,32,8,20,32,2,1,32,18,20>(
		image_in,
		conv1_weights,
		conv1_factorsA,
		conv1_factorsB,
		conv1_out_stream,
		1 // batch_size
	);

	stream<POOL1_OUT_T> pool1_out_stream("pool1_out_stream");
	// K,S,Din,Cin,Ibit
	POOL2D_KP<3,2,32,32,2>(
		conv1_out_stream,
		pool1_out_stream,
		1 // batch_size
	);

	stream<FIRE1_OUT_T> fire1_out_stream("fire1_out_stream");
	// sq_K,sq_S,sq_Din,sq_Cin,sq_Cout,sq_Ibit,sq_Wbit,sq_Mbit,sq_Abit,sq_MVTU_InP,sq_MVTU_OutP,ex_K,ex_S,ex_Din,ex_Cin,ex_Cout,ex_Ibit,ex_Wbit,ex_Mbit,ex_Abit,ex_MVTU_InP,ex_MVTU_OutP,ScaleBits,FactorScaleBits
	HALFFIRE_ACT<1,1,16,32,16,2,20,32,2,32,16,3,1,16,16,20,2,20,32,2,16,20,18,20>(
		pool1_out_stream,
		squeeze_fire1_weights,
		squeeze_fire1_factorsA,
		squeeze_fire1_factorsB,
		expand_fire1_weights,
		expand_fire1_factorsA,
		expand_fire1_factorsB,
		fire1_out_stream,
		1 // batch_size
	);

	stream<POOL2_OUT_T> pool2_out_stream("pool2_out_stream");
	// K,S,Din,Cin,Ibit
	POOL2D_KP<3,2,16,20,2>(
		fire1_out_stream,
		pool2_out_stream,
		1 // batch_size
	);

	stream<FIRE2_OUT_T> fire2_out_stream("fire2_out_stream");
	// sq_K,sq_S,sq_Din,sq_Cin,sq_Cout,sq_Ibit,sq_Wbit,sq_Mbit,sq_Abit,sq_MVTU_InP,sq_MVTU_OutP,ex_K,ex_S,ex_Din,ex_Cin,ex_Cout,ex_Ibit,ex_Wbit,ex_Mbit,ex_Abit,ex_MVTU_InP,ex_MVTU_OutP,ScaleBits,FactorScaleBits
	HALFFIRE_ACT<1,1,8,20,16,2,20,32,2,20,16,3,1,8,16,20,2,20,32,2,16,20,18,20>(
		pool2_out_stream,
		squeeze_fire2_weights,
		squeeze_fire2_factorsA,
		squeeze_fire2_factorsB,
		expand_fire2_weights,
		expand_fire2_factorsA,
		expand_fire2_factorsB,
		fire2_out_stream,
		1 // batch_size
	);

	stream<POOL3_OUT_T> pool3_out_stream("pool3_out_stream");
	// K,S,Din,Cin,Ibit
	POOL2D_KP<3,2,8,20,2>(
		fire2_out_stream,
		pool3_out_stream,
		1 // batch_size
	);

	stream<FIRE3_OUT_T> fire3_out_stream("fire3_out_stream");
	// sq_K,sq_S,sq_Din,sq_Cin,sq_Cout,sq_Ibit,sq_Wbit,sq_Mbit,sq_Abit,sq_MVTU_InP,sq_MVTU_OutP,ex_K,ex_S,ex_Din,ex_Cin,ex_Cout,ex_Ibit,ex_Wbit,ex_Mbit,ex_Abit,ex_MVTU_InP,ex_MVTU_OutP,ScaleBits,FactorScaleBits
	HALFFIRE_ACT<1,1,4,20,16,2,20,32,2,20,16,3,1,4,16,20,2,20,32,2,16,20,18,20>(
		pool3_out_stream,
		squeeze_fire3_weights,
		squeeze_fire3_factorsA,
		squeeze_fire3_factorsB,
		expand_fire3_weights,
		expand_fire3_factorsA,
		expand_fire3_factorsB,
		fire3_out_stream,
		1 // batch_size
	);

    stream<CONV_CLASS_OUT_T> conv_class_out_stream("conv_class_out_stream");

    // Din, Cin, Cout, Ibit, TWScalebit, Mbit, PoolAccBit, MVTU_InP, MVTU_OutP
    TW_CONV2D_1x1_NOACT_NoP_GAP<4,20,512,2,8,2,16,32,20,32>(
        fire3_out_stream,
        conv_class_weights,
        conv_class_Wp,
        conv_class_Wn,
        conv_class_out_stream,
        1 // batch_size
    );

    SoftMax<512,64,32,1>( // SoftMax<512,64,32,1>(
        conv_class_out_stream,
        pred_out,
        1 // batch_size
    );
}


void model_wrapper(
		stream<ap_int<IorQ_W> >& i_in,
		stream<ap_int<IorQ_W> >& q_in,
		AXIS_OUT &axis_pred_out
){
#pragma HLS INTERFACE ap_ctrl_none port=return
#pragma HLS INTERFACE axis port=i_in
#pragma HLS INTERFACE axis port=q_in
#pragma HLS INTERFACE axis port=axis_pred_out
#pragma HLS DATAFLOW

	stream<PRED_T> pred_out;
	const int out_size = 256; // 256

	model(i_in, q_in, pred_out);

	OUT_LOOP_1: for (int j = 0; j < out_size; j++) {
#pragma HLS UNROLL
		axis_out tmp_out;
		tmp_out.data = (ap_uint<8>)pred_out.read();
		if(j == (out_size-1))
			tmp_out.last = 1;
		else
			tmp_out.last = 0;
		axis_pred_out.write(tmp_out);
	}
}
